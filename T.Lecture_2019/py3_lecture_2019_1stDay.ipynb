{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Python Basic(1)\n",
    "1. Data Type\n",
    "2. List, Tuple, Dictionary\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Data Type ***\n",
      "a=17 type=<class 'int'>\n",
      "b=7 type=<class 'int'>\n",
      "c=2.4285714285714284 type=<class 'float'>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Data Type ***\")\n",
    "### Integer and float numbers\n",
    "a=17\n",
    "b=7\n",
    "c=a/b\n",
    "print(\"a={} type={}\".format(a,type(a)))\n",
    "print(\"b={} type={}\".format(b,type(b)))\n",
    "print(\"c={} type={}\".format(c,type(c)))\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17, 17, 17, 007, 2.43\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_test = '{}, {:d}, {:02d}, {:03d}, {:.2f}'.format(a,a,a,b,c)\n",
    "print(format_test)\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=2.4285714285714284 type=<class 'str'>\n",
      "18 2.42 284\n",
      "4.857142857142857\n",
      "2.42857142857142842.4285714285714284\n",
      "36\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### String\n",
    "d=str(c)\n",
    "print(\"d={} type={}\".format(c,type(d)))\n",
    "print(len(d),d[0:4],d[-3:])\n",
    "c+=c  ## c=c+c\n",
    "print(c)\n",
    "d+=d  ## d=d+d\n",
    "print(d)\n",
    "print(len(d))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unicode Test\n",
      "El Niño\n",
      "Delta: Δ, epsilon: ε, degree: °\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Printing unicode\n",
    "print(\"Unicode Test\")\n",
    "print(\"El Ni\\u00F1o\")\n",
    "print(\"Delta: {}, epsilon: {}, degree: {}\".format('\\u0394','\\u03B5','\\u00B0'))\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boo1=True type=<class 'bool'>\n",
      "Value of bools\n",
      "1 0\n",
      "True+False= 1\n",
      "True and False= False\n",
      "bool(-1)=True, bool(0)=False, bool(1)=True, bool(2)=True\n",
      "bool(-0.1)=True, bool(0.)=False, bool(0.1)=True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Boolean\n",
    "boo1, boo2 = True, False\n",
    "print(\"boo1={} type={}\".format(boo1,type(boo1)))\n",
    "print(\"Value of bools\")\n",
    "print(int(boo1),int(boo2))\n",
    "print(\"True+False=\",boo1+boo2)\n",
    "print(\"True and False=\",boo1 and boo2)\n",
    "print(\"bool(-1)={}, bool(0)={}, bool(1)={}, bool(2)={}\".format(bool(-1),bool(0),bool(1),bool(2)))\n",
    "print(\"bool(-0.1)={}, bool(0.)={}, bool(0.1)={}\".format(bool(-0.1),bool(0.),bool(0.1)))\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** List ***\n",
      "e=[17, 7, 4.857142857142857] type=<class 'list'>\n",
      "e+e=[17, 7, 4.857142857142857, 17, 7, 4.857142857142857]\n",
      "\n",
      " This is not a copy\n",
      "[5, 7, 4.857142857142857]\n",
      "[5, 7, 4.857142857142857]\n",
      "[4, 7, 4.857142857142857]\n"
     ]
    }
   ],
   "source": [
    "###---- List\n",
    "print(\"*** List ***\")\n",
    "e=[a,b,c]\n",
    "print(\"e={} type={}\".format(e,type(e)))\n",
    "print(\"e+e={}\".format(e+e))\n",
    "print(\"\\n This is not a copy\")\n",
    "e2=e\n",
    "e2[0]=5\n",
    "print(e)\n",
    "e3=e[:]\n",
    "e3[0]=4\n",
    "print(e)\n",
    "print(e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** List ***\n",
      "e=[17, 7, 4.857142857142857] type=<class 'list'>\n",
      "e+e=[17, 7, 4.857142857142857, 17, 7, 4.857142857142857]\n",
      "\n",
      " This is not a copy\n",
      "[5, 7, 4.857142857142857]\n",
      "[5, 7, 4.857142857142857]\n",
      "[4, 7, 4.857142857142857]\n"
     ]
    }
   ],
   "source": [
    "###---- List\n",
    "print(\"*** List ***\")\n",
    "e=[a,b,c]\n",
    "print(\"e={} type={}\".format(e,type(e)))\n",
    "print(\"e+e={}\".format(e+e))\n",
    "print(\"\\n This is not a copy\")\n",
    "e2=e\n",
    "e2[0]=5\n",
    "print(e)\n",
    "e3=e[:]\n",
    "e3[0]=4\n",
    "print(e)\n",
    "print(e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.857142857142857, 5, 7] [4.857142857142857, 5, 7]\n",
      "* min, max, sum\n",
      "4.857142857142857 7 16.857142857142858\n",
      "\n",
      "\n",
      "* Slicing\n",
      "[5, 7, 4.857142857142857]\n",
      "[5, 4.857142857142857]\n",
      "[4.857142857142857, 7, 5]\n",
      "\n",
      "\n",
      "* Map(func, iter)\n",
      "['abc', 'def', 'ghi']\n",
      "list(map(list,aa))= [['a', 'b', 'c'], ['d', 'e', 'f'], ['g', 'h', 'i']]\n",
      "['a', 'b', 'c']\n",
      "[0, 1, 2, 3, 4]\n",
      "list(map(float,cc)) [0.0, 1.0, 2.0, 3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# e.sort()   ### This causes an error because strs and numbers are mixed in\n",
    "f=e[:5]\n",
    "f.sort()\n",
    "print(f,sorted(e[:5]))\n",
    "print(\"* min, max, sum\")\n",
    "print(min(e[:5]),max(e[:5]),sum(e[:5]))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"* Slicing\")\n",
    "print(e)\n",
    "print(e[::2]) ### = e[0:len(e):2]\n",
    "print(e[::-1])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"* Map(func, iter)\")\n",
    "aa=['abc','def','ghi']\n",
    "bb=list(map(list,aa))\n",
    "print(aa)\n",
    "print(\"list(map(list,aa))=\",bb)\n",
    "print(list(aa[0]))\n",
    "cc=list(range(5))\n",
    "dd=list(map(float,cc))\n",
    "print(cc)\n",
    "print(\"list(map(float,cc))\",dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "g=(1, 2, 3) type=<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "###--- Tuple\n",
    "g=(1,2,3)\n",
    "print(\"\\ng={} type={}\".format(g,type(g)))\n",
    "# g[0]=10 ### This causes an error because Tuple prohibits assignment \n",
    "# g.append(4) ### Of course, no modification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h={'brand': 'Ford', 'model': 'Mustang', 'year': 1964} type=<class 'dict'>\n",
      "1964\n"
     ]
    }
   ],
   "source": [
    "###--- Dictionary\n",
    "h = {\"brand\": \"Ford\", \"model\": \"Mustang\", \"year\": 1964 }\n",
    "print(\"h={} type={}\".format(h,type(h)))\n",
    "print(h[\"year\"])  ### Access value by key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Python Basic(2)\n",
    "3. IF\n",
    "4. FOR\n",
    "5. WHILE\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### If basic\n",
    "if True:\n",
    "   print(\"IF True\\n\")\n",
    "elif False:\n",
    "   print(\"Not printing here\")\n",
    "else:\n",
    "   print(\"Not printing here\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 6, 9, 12, 15, 18]\n",
      "[1, 4, 7, 10, 13, 16, 19]\n",
      "[2, 5, 8, 11, 14, 17] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### For basic\n",
    "list1, list2, list3 = [], [], []\n",
    "for i in range(20):\n",
    "### range(20) = range(0,20) = range(0,20,1)\n",
    "   if i%3==0:\n",
    "      list1.append(i)\n",
    "   elif i%3==1:\n",
    "      list2.append(i)\n",
    "   else:\n",
    "      list3.append(i)\n",
    "\n",
    "print(list1)\n",
    "print(list2)\n",
    "print(list3, '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "34\n",
      "67\n",
      "910\n",
      "1213\n",
      "1516\n",
      "1819\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### For + zip\n",
    "list4=[]\n",
    "for i,j in zip(list1,list2):\n",
    "   list4.append(str(i)+str(j))\n",
    "#print(list4)\n",
    "for a in list4:\n",
    "   print(a)\n",
    "\n",
    "print('\\n')\n",
    "list5=[]\n",
    "for i,j,k in zip(list1,list2,list3):\n",
    "   list5.append(str(i)+str(j)+str(k))\n",
    "#print(list5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 012\n",
      "1 345\n",
      "2 678\n",
      "3 91011\n",
      "4 121314\n",
      "5 151617\n"
     ]
    }
   ],
   "source": [
    "### For + enumerate\n",
    "for i,a in enumerate(list5):\n",
    "   print(i,a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "12\n",
      "344\n",
      "676\n",
      "91008\n",
      "121310\n",
      "151612\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### While\n",
    "print('\\n')\n",
    "i=0\n",
    "while i<len(list5):\n",
    "   print(int(list5[i])-i)\n",
    "   i+=1\n",
    "\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Functions\n",
    "def test_function():\n",
    "   #Some contents\n",
    "   return \"Yes\"\n",
    "\n",
    "print(test_function(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Simple Function Example\n",
      "   Argument \"num\" should be >0\n",
      "   \n",
      "20\n",
      "2450\n",
      "Input should be >0\n",
      "-999 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "###---\n",
    "\n",
    "def sum_every2(num):\n",
    "   '''\n",
    "   Simple Function Example\n",
    "   Argument \"num\" should be >0\n",
    "   '''\n",
    "   if num<=0:\n",
    "      print(\"Input should be >0\")\n",
    "      return -999\n",
    "\n",
    "   sum1=0\n",
    "   for i in range(0,num,2):\n",
    "      sum1+=i\n",
    "\n",
    "   return sum1\n",
    "\n",
    "print(sum_every2.__doc__)\n",
    "print(sum_every2(10))\n",
    "print(sum_every2(100))\n",
    "print(sum_every2(-1),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: Simple version (lambda)\n",
      "20\n",
      "2450\n",
      "-999 \n",
      "\n",
      "Function with default value(s)\n",
      "\n",
      "   Simple Function Example with default argument\n",
      "   Arg \"num\" should be >0\n",
      "   Arg \"n\" default value is 2\n",
      "   \n",
      "20\n",
      "1683\n",
      "1683\n",
      "1683\n",
      "Input should be >0\n",
      "-999 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "###---\n",
    "print(\"Function: Simple version (lambda)\")\n",
    "sum_ev2 = lambda num: sum(list(range(0,num,2))) if num>0 else -999\n",
    "print(sum_ev2(10))\n",
    "print(sum_ev2(100))\n",
    "print(sum_ev2(-1),'\\n')\n",
    "\n",
    "\n",
    "print(\"Function with default value(s)\")\n",
    "def sum_every_n(num,n=2):\n",
    "   '''\n",
    "   Simple Function Example with default argument\n",
    "   Arg \"num\" should be >0\n",
    "   Arg \"n\" default value is 2\n",
    "   '''\n",
    "   if num<=0:\n",
    "      print(\"Input should be >0\")\n",
    "      return -999\n",
    "\n",
    "   sum1=0\n",
    "   for i in range(0,num,n):\n",
    "      sum1+=i\n",
    "\n",
    "   return sum1\n",
    "\n",
    "print(sum_every_n.__doc__)\n",
    "print(sum_every_n(10))\n",
    "print(sum_every_n(100,3))\n",
    "print(sum_every_n(100,n=3))\n",
    "print(sum_every_n(num=100,n=3))\n",
    "print(sum_every_n(-1),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0E,0N)= 180 90\n"
     ]
    }
   ],
   "source": [
    "###---\n",
    "from math import ceil\n",
    "def lon_deg2x(lon,lon0,dlon):\n",
    "    x=ceil((lon-lon0)/dlon)\n",
    "    if lon0<0 and lon>180:\n",
    "        x-= int(360/dlon)\n",
    "    if lon0>0 and lon<0:\n",
    "        x+= int(360/dlon)\n",
    "\n",
    "    return x\n",
    "lat_deg2y = lambda lat,lat0,dlat: ceil((lat-lat0)/dlat)\n",
    "\n",
    "lon0=-179.5; dlon=1.\n",
    "lat0=-89.5; dlat=1.\n",
    "print(\"(0E,0N)=\",lon_deg2x(0,lon0,dlon),lat_deg2y(0,lat0,dlat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A03.file_name_change.py3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from subprocess import call\n",
    "\n",
    "indir='./data/'\n",
    "fnames=glob.glob(indir+'*.*')\n",
    "\n",
    "#modified by me start\n",
    "#print(fnames)\n",
    "#modified by me end\n",
    "\n",
    "# At present, there is no file with \":\" in its file name so nothing will happen. \n",
    "for fn in fnames:\n",
    "    if \":\" in fn:\n",
    "        print(fn)\n",
    "        fn2=fn.replace(\":\",\"-\")\n",
    "\n",
    "        print(\"Changed: \"+fn2)\n",
    "        call([\"mv\",fn,fn2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "from subprocess import call\n",
    "#from pyhdf.SD import SD, SDC\n",
    "import h5py\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import matplotlib.colors as cls\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator, FixedLocator, MultipleLocator\n",
    "\n",
    "#import cartopy.crs as ccrs\n",
    "#from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from scipy.stats import kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess if no errors!\n"
     ]
    }
   ],
   "source": [
    "print(\"Sucess if no errors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Numpy - basic methods\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_array_info(a,show_contents=True):\n",
    "   \"\"\" \n",
    "   Print information of numpy array\n",
    "   \"\"\"\n",
    "   result=\"N_Dims={}, Shape={}, Data_Type={}\".format(a.ndim, a.shape, a.dtype)\n",
    "   print(result)\n",
    "   if show_contents:\n",
    "      print(a)\n",
    "   return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "np.zeros\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=float64\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "np.ones\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n",
      "\n",
      "np.empty\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=float32\n",
      "[[-3.1484815e-05  1.5304982e-41 -3.1484960e-05  1.5304982e-41]\n",
      " [ 2.3822074e-44  1.5304982e-41  2.3267113e+13  3.0611365e-41]\n",
      " [-1.9942292e-10  1.5304982e-41  2.8025969e-45  2.7952212e+20]]\n",
      "\n",
      "np.full\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=float64\n",
      "[[-999.9 -999.9 -999.9 -999.9]\n",
      " [-999.9 -999.9 -999.9 -999.9]\n",
      " [-999.9 -999.9 -999.9 -999.9]]\n",
      "\n",
      "np.array\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "\n",
      "np.asarray\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "\n",
      "np.asfarray\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=float64\n"
     ]
    }
   ],
   "source": [
    "### Make new array\n",
    "zeros = np.zeros([3,4])\n",
    "ones = np.ones([3,4],dtype=int)\n",
    "empty = np.empty([3,4],dtype=np.float32)\n",
    "full = np.full_like(zeros,-999.9)\n",
    "print('\\nnp.zeros') ;show_array_info(zeros)\n",
    "print('\\nnp.ones')  ;show_array_info(ones)\n",
    "print('\\nnp.empty') ;show_array_info(empty)\n",
    "print('\\nnp.full') ;show_array_info(full)\n",
    "\n",
    "a=[[0,1,2,3],[4,5,6,7],[8,9,10,11]]  ### A list\n",
    "b=np.array(a)\n",
    "c=np.asarray(a)\n",
    "d=np.asfarray(a)\n",
    "\n",
    "print('\\nnp.array') ;show_array_info(b)\n",
    "print('\\nnp.asarray')  ;show_array_info(c,show_contents=False)\n",
    "print('\\nnp.asfarray') ;show_array_info(d,show_contents=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "np.arange(12) (12,)\n",
      "\n",
      " After Reshape\n",
      "N_Dims=2, Shape=(4, 3), Data_Type=int64\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "\n",
      " After Transpose\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[ 0  3  6  9]\n",
      " [ 1  4  7 10]\n",
      " [ 2  5  8 11]]\n",
      "\n",
      " np.linspace(1,10,4)\n",
      "N_Dims=1, Shape=(4,), Data_Type=float64\n",
      "[ 1.  4.  7. 10.]\n"
     ]
    }
   ],
   "source": [
    "e=np.arange(12)  ### Similar to range()\n",
    "print('\\nnp.arange(12)',e.shape)\n",
    "e=np.reshape(e,[4,3])   ### Reshape: Very Important!\n",
    "print('\\n After Reshape')\n",
    "show_array_info(e)\n",
    "e=e.T  ### Same: transpose()\n",
    "print('\\n After Transpose')\n",
    "show_array_info(e)\n",
    "# e=np.arange(12).reshape([4,3])\n",
    "\n",
    "f=np.linspace(1,10,4)\n",
    "print('\\n np.linspace(1,10,4)'); show_array_info(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Adding Array\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[2 2 2 2]\n",
      " [2 2 2 2]\n",
      " [2 2 2 2]]\n",
      "\n",
      " Adding Int Array and Float Array\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=float64\n",
      "[[-998.9 -998.9 -998.9 -998.9]\n",
      " [-998.9 -998.9 -998.9 -998.9]\n",
      " [-998.9 -998.9 -998.9 -998.9]]\n",
      "\n",
      " Array*Array\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[4 4 4 4]\n",
      " [4 4 4 4]\n",
      " [4 4 4 4]]\n",
      "\n",
      " Array*number\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[12 12 12 12]\n",
      " [12 12 12 12]\n",
      " [12 12 12 12]]\n",
      "\n",
      " Array_2D*Array_1D\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=float64\n",
      "[[ 4. 16. 28. 40.]\n",
      " [ 4. 16. 28. 40.]\n",
      " [ 4. 16. 28. 40.]]\n"
     ]
    }
   ],
   "source": [
    "### Simple operation\n",
    "print('\\n Adding Array')\n",
    "tmp_plus= ones+ones\n",
    "show_array_info(tmp_plus)\n",
    "\n",
    "print('\\n Adding Int Array and Float Array')\n",
    "tmp_plus2= ones+full\n",
    "show_array_info(tmp_plus2)\n",
    "\n",
    "print('\\n Array*Array')\n",
    "tmp_multiply= tmp_plus*tmp_plus\n",
    "show_array_info(tmp_multiply)\n",
    "\n",
    "print('\\n Array*number')\n",
    "tmp_multiply2= tmp_multiply*3\n",
    "show_array_info(tmp_multiply2)\n",
    "\n",
    "print('\\n Array_2D*Array_1D')\n",
    "tmp_multiply3= tmp_multiply*f[None,:]\n",
    "show_array_info(tmp_multiply3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Copy or not?\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[2 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n",
      "\n",
      " Copy or not?\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[2 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n",
      "\n",
      " Copy or not?\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[4 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "### Copy or not copy\n",
    "ones2=ones\n",
    "ones2[0,0]=2\n",
    "print('\\n Copy or not?')\n",
    "show_array_info(ones)\n",
    "\n",
    "ones3=np.copy(ones)\n",
    "ones3[0,0]=3\n",
    "print('\\n Copy or not?')\n",
    "show_array_info(ones)\n",
    "\n",
    "ones4=ones[:]\n",
    "ones4[0,0]=4\n",
    "print('\\n Copy or not?')\n",
    "show_array_info(ones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting Array before Transformation\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int64\n",
      "[[ 0  3  6  9]\n",
      " [ 1  4  7 10]\n",
      " [ 2  5  8 11]]\n",
      "\n",
      " Array.astype(np.int16)\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int16\n",
      "\n",
      " Partial sum of array\n",
      "N_Dims=2, Shape=(3, 2), Data_Type=int64\n",
      "[[ 3 15]\n",
      " [ 5 17]\n",
      " [ 7 19]]\n",
      "\n",
      " Swap Axes\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=int16\n",
      "[[ 0  6  3  9]\n",
      " [ 1  7  4 10]\n",
      " [ 2  8  5 11]]\n",
      "\n",
      " Slicing with index list [:,[1,3]]\n",
      "N_Dims=2, Shape=(3, 2), Data_Type=int16\n",
      "[[ 6  9]\n",
      " [ 7 10]\n",
      " [ 8 11]]\n"
     ]
    }
   ],
   "source": [
    "### Transform the array\n",
    "print('\\n Starting Array before Transformation')\n",
    "show_array_info(e)\n",
    "\n",
    "print('\\n Array.astype(np.int16)')\n",
    "e2=e.astype(np.int16)\n",
    "show_array_info(e2,show_contents=False)\n",
    "\n",
    "print('\\n Partial sum of array')\n",
    "show_array_info(e2.reshape([3,2,2]).sum(axis=2))\n",
    "\n",
    "print('\\n Swap Axes')\n",
    "e2=e2.reshape([-1,2,2]).swapaxes(1,2).reshape([-1,4]) ### \"-1\" in reshape means \"all others\"\n",
    "show_array_info(e2)\n",
    "\n",
    "print('\\n Slicing with index list [:,[1,3]]')\n",
    "index_list=[1,3]\n",
    "e3=e2[:,index_list]\n",
    "show_array_info(e3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Find location satisfying specific condition\n",
      "<class 'tuple'> 2\n",
      "j=0, i=1, value=6\n",
      "j=0, i=3, value=9\n",
      "j=1, i=1, value=7\n",
      "j=2, i=1, value=8\n",
      "\n",
      " Usually don't need to know the location\n",
      "N_Dims=2, Shape=(3, 4), Data_Type=bool\n",
      "[[False  True False  True]\n",
      " [False  True False False]\n",
      " [False  True False False]]\n",
      "N_Dims=1, Shape=(4,), Data_Type=int16\n",
      "[6 9 7 8]\n"
     ]
    }
   ],
   "source": [
    "### Indexing\n",
    "print('\\n Find location satisfying specific condition')\n",
    "loc=np.where(np.logical_and(e2>5,e2<10))\n",
    "print(type(loc),len(loc))\n",
    "for j,i in zip(*loc):\n",
    "  print(\"j={}, i={}, value={}\".format(j,i,e2[j,i]))\n",
    "\n",
    "print('\\n Usually don\\'t need to know the location')\n",
    "idx=np.logical_and(e2>5,e2<10)\n",
    "show_array_info(idx)\n",
    "show_array_info(e2[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "### Logical operation\n",
    "np.logical_and()\n",
    "np.logical_or()\n",
    "np.logical_not()\n",
    "\n",
    "### Expanding Array\n",
    "repeat()\n",
    "np.tile()\n",
    "np.concatenate()\n",
    "np.hstack()\n",
    "np.vstack()\n",
    "\n",
    "### Simple statistical methods\n",
    "dot()\n",
    "max()\n",
    "mean(); np.average()\n",
    "min()\n",
    "sum()\n",
    "std()\n",
    "var()\n",
    "np.median()\n",
    "np.around()\n",
    "sort()\n",
    "np.cumsum()\n",
    "np.percentile()\n",
    "np.digitize()\n",
    "np.histogram()\n",
    "np.corrcoef()\n",
    "\n",
    "### Argument methods\n",
    "argmax() # Return index of maximum value\n",
    "argmin()\n",
    "argsort()\n",
    "\n",
    "### Mathematical functions\n",
    "np.sin()\n",
    "np.cos()\n",
    "np.around()\n",
    "np.floor()\n",
    "np.ceil()\n",
    "np.power()\n",
    "np.log()\n",
    "np.exp()\n",
    "\n",
    "### Checking data\n",
    "np.isnan()\n",
    "np.isinf()\n",
    "np.isfinite()\n",
    "\n",
    "### Treat NaN values\n",
    "np.nan_to_num()\n",
    "np.nansum()\n",
    "\n",
    "### https://docs.scipy.org/doc/numpy/reference/\n",
    "\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B02.binary_read_write+RMS_of_MonthlyData.py3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_file_read2mtx(fname,dtype=np.float32):\n",
    "    \"\"\" Open a binary file, and read data \n",
    "        fname : file name\n",
    "        dtype   : data type; np.float32 or np.float64, etc. \"\"\"\n",
    "\n",
    "    if not os.path.isfile(fname):\n",
    "        #print( \"File does not exist:\"+fname); sys.exit()\n",
    "        sys.exit(\"File does not exist:\"+fname)\n",
    "\n",
    "    #fd=open(fname,'rb')\n",
    "    with open(fname,'rb') as f:\n",
    "        bin_mat = np.fromfile(file=f,dtype=dtype)\n",
    "    #fd.close() ### Not needed with \"with\"\n",
    "\n",
    "    return bin_mat\n",
    "\n",
    "from math import ceil\n",
    "def lon_deg2x(lon,lon0,dlon):\n",
    "    x=ceil((lon-lon0)/dlon)\n",
    "    if lon0<0 and lon>180:\n",
    "        x-= int(360/dlon)\n",
    "    if lon0>0 and lon<0:\n",
    "        x+= int(360/dlon)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_deg2y = lambda lat,lat0,dlat: ceil((lat-lat0)/dlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348, 180, 360)\n"
     ]
    }
   ],
   "source": [
    "###---- Main\n",
    "\n",
    "##-- Parameters\n",
    "indir='./data/'\n",
    "fname=indir+'HadISST1.sample.348x180x360.f32dat'\n",
    "\n",
    "nt=348 ### Monthly for 29 years\n",
    "nlon=360; lon0=0.5; dlon=1.\n",
    "nlat=180; lat0=-89.5; dlat=1.\n",
    "\n",
    "undef= -9999.\n",
    "\n",
    "##-- Read binary file\n",
    "sst=bin_file_read2mtx(fname)  ### \"dtype=np.float32\" is omitted. \n",
    "sst=sst.reshape([nt,nlat,nlon])\n",
    "print(sst.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 160] [65, 115]\n",
      "(348, 50, 100)\n"
     ]
    }
   ],
   "source": [
    "##-- Sampling for limited regiosn (60E-160E,25S-25N)\n",
    "lon_deg_range=[60,160]\n",
    "lat_deg_range=[-25,25]\n",
    "\n",
    "lon_idx=[lon_deg2x(x,lon0,dlon) for x in lon_deg_range]; nlon2=lon_idx[1]-lon_idx[0]\n",
    "lat_idx=[lat_deg2y(y,lat0,dlat) for y in lat_deg_range]; nlat2=lat_idx[1]-lat_idx[0]\n",
    "print(lon_idx, lat_idx)\n",
    "sst=sst[:,lat_idx[0]:lat_idx[1],lon_idx[0]:lon_idx[1]]\n",
    "print(sst.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 100) 799\n"
     ]
    }
   ],
   "source": [
    "##-- Identify missings\n",
    "msidx= sst<-100\n",
    "msidx=msidx.sum(axis=0).astype(bool) ### For identify gridcells having any missings for all time\n",
    "print(msidx.shape,msidx.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 50, 100)\n"
     ]
    }
   ],
   "source": [
    "##-- Remove annual cycle\n",
    "#- 1. Calc annual cycle\n",
    "anncyl= sst.reshape([-1,12,nlat2,nlon2]).mean(axis=0)\n",
    "print(anncyl.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71170914 0.1314251\n"
     ]
    }
   ],
   "source": [
    "#- 2. Calc anomalies\n",
    "sstano= sst.reshape([-1,12,nlat2,nlon2])-anncyl[None,:,:,:]\n",
    "sstano= sstano.reshape([nt,nlat2,nlon2])\n",
    "\n",
    "##-- Calc Root-Mean-Squared-Sum of anomalies\n",
    "rms= np.sqrt(np.mean(sstano*sstano,axis=0))\n",
    "print(rms[~msidx].max(), rms[~msidx].min())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##-- Restore missings\n",
    "rms[msidx]=undef\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Write to binary file\n",
    "outdir=indir\n",
    "outfn=outdir+'HadSST_rms.{}x{}.f32dat'.format(nlat2,nlon2)\n",
    "\n",
    "##-- Protect existing file\n",
    "if os.path.isfile(outfn):\n",
    "    sys.exit(\"Already Exist: \"+outfn)\n",
    "else:\n",
    "    with open(outfn, 'wb') as f:\n",
    "        rms.astype(np.float32).tofile(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C01.Text_read_write+Regression+Density.py3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 4) (17, 4)\n"
     ]
    }
   ],
   "source": [
    "###---- Main\n",
    "\n",
    "##-- Parameters\n",
    "indir='./data/'\n",
    "fname=indir+'storm_track.txt'\n",
    "\n",
    "data=[]; time_info=[]\n",
    "with open(fname,'r') as f:\n",
    "    for i,line in enumerate(f):\n",
    "        words=line.strip().split()\n",
    "        #print(i,words)\n",
    "\n",
    "        if i>0:  ### Exclude header\n",
    "            flos=list(map(float,words[:4]))\n",
    "            ints=list(map(int,words[4:]))\n",
    "\n",
    "            data.append(flos)\n",
    "            time_info.append(ints)\n",
    "\n",
    "\n",
    "\n",
    "data=np.asarray(data)\n",
    "time_info=np.asarray(time_info)\n",
    "\n",
    "print(data.shape, time_info.shape)\n",
    "\n",
    "###-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff.=-1.41, Intercept=1023.97, R² Score=0.707\n"
     ]
    }
   ],
   "source": [
    "###--- Linear Regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "## For linear-regression\n",
    "regr=linear_model.LinearRegression()   ### Initiate Regression Object\n",
    "\n",
    "xdata=data[:,2].reshape([-1,1])  ## wind speed\n",
    "ydata=data[:,3].reshape([-1,1])  ## surface pressure\n",
    "\n",
    "regr.fit(xdata,ydata)\n",
    "r2score=regr.score(xdata,ydata)\n",
    "print(u\"Coeff.={:.2f}, Intercept={:.2f}, R\\u00B2 Score={:.3f}\".format(regr.coef_[0][0], regr.intercept_[0],r2score))\n",
    "\n",
    "#y_pred=regr.predict(xcoord)\n",
    "regr.__init__()     ### Re-initiate in order to use next time with different data\n",
    "\n",
    "\n",
    "###-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,) 4929\n",
      "Max Density is 0.00442 when wind speed=26.24 and pressure=983.44\n"
     ]
    }
   ],
   "source": [
    "### Calculate density of data\n",
    "from scipy.stats import kde\n",
    "\n",
    "xdata=data[:,2]  ## wind speed\n",
    "ydata=data[:,3]  ## surface pressure\n",
    "k=kde.gaussian_kde([xdata,ydata])\n",
    "xi,yi=np.mgrid[xdata.min():xdata.max():100j,ydata.min():ydata.max():100j]\n",
    "zi=k(np.vstack([xi.flatten(),yi.flatten()]))\n",
    "\n",
    "print(zi.shape, zi.argmax())\n",
    "\n",
    "j,i=np.unravel_index(zi.argmax(),xi.shape)\n",
    "xloc= xdata.min()+(xdata.max()-xdata.min())/100*i\n",
    "yloc= ydata.min()+(ydata.max()-ydata.min())/100*j\n",
    "print(\"Max Density is {:.05f} when wind speed={:.2f} and pressure={:.2f}\".format(zi.max(),xloc,yloc))\n",
    "\n",
    "\n",
    "###-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "### Write to text file\n",
    "\n",
    "outdir = indir\n",
    "outfn = outdir+'text_write_ex1.txt'\n",
    "\n",
    "##-- Protect existing file\n",
    "if os.path.isfile(outfn):\n",
    "    sys.exit(\"Already Exist: \"+outfn)\n",
    "else:\n",
    "    with open(outfn,'w') as f:\n",
    "        header=\"Longitude, Wind, Year, Month\"\n",
    "        f.write(header+\"\\n\")\n",
    "        \n",
    "        #modified by me start\n",
    "        print(data.shape[0])\n",
    "        #modified by me end\n",
    "\n",
    "        for i in range(data.shape[0]):\n",
    "            data_txt=\"{:.2f}, {:.2f}, {:d}, {:02d}\".format(data[i,0],data[i,2],time_info[i,0],time_info[i,1])\n",
    "            f.write(data_txt+\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C02a.HDF4_file_header_info.py3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyhdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-ef6c1599348f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyhdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSD\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSDC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyhdf'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Print header information of HDF4 file\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "from subprocess import call\n",
    "from pyhdf.SD import SD, SDC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_hdf4(fname):\n",
    "    if not os.path.isfile(fname):\n",
    "        print(\"File does not exist:\"+fname)\n",
    "        sys.exit()\n",
    "\n",
    "    hid=SD(fname,SDC.READ)\n",
    "    print(\"Open:\",fname)\n",
    "    return hid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-41b8ad8b7d72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'3B42.20180218.00.7.HDF'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhdf_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_hdf4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdinfo\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhdf_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-6aaca28ad605>\u001b[0m in \u001b[0;36mopen_hdf4\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mhid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSDC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Open:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SD' is not defined"
     ]
    }
   ],
   "source": [
    "##-- Parameters\n",
    "indir='./data/'\n",
    "fname=indir+'3B42.20180218.00.7.HDF'\n",
    "\n",
    "hdf_f = open_hdf4(fname)\n",
    "\n",
    "dinfo= hdf_f.datasets()\n",
    "#print(hdf_f.datasets())\n",
    "for dd in dinfo:\n",
    "    print(\"Name: {}\".format(dd))\n",
    "    print(\"   Values: {}\".format(dinfo[dd]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nh5keys=[]\\nhdf_f.visit(h5keys.append)\\n\\n\\nit=13\\nprint(\"\\n{}\".format(h5keys[it]))\\ndset=hdf_f[h5keys[it]]\\nfor (name, val) in dset.attrs.items():\\n    print(\"Name: {}\".format(name))\\n    print(\"   Values: {}\".format(val))\\n\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "h5keys=[]\n",
    "hdf_f.visit(h5keys.append)\n",
    "\n",
    "\n",
    "it=13\n",
    "print(\"\\n{}\".format(h5keys[it]))\n",
    "dset=hdf_f[h5keys[it]]\n",
    "for (name, val) in dset.attrs.items():\n",
    "    print(\"Name: {}\".format(name))\n",
    "    print(\"   Values: {}\".format(val))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C02b.HDF5_file_header_info.py3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print header information of HDF5 file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_hdf5(fname):\n",
    "    if not os.path.isfile(fname):\n",
    "        print(\"File does not exist:\"+fname)\n",
    "        sys.exit()\n",
    "\n",
    "    hid=h5py.File(fname,'r')\n",
    "    print(\"Open:\",fname)\n",
    "    return hid\n",
    "\n",
    "def printname(name):\n",
    "    global i\n",
    "    print(i,name)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open: ./data/AERDB_L2_VIIRS_SNPP.A2014067.1936.001.2019056041229.nc\n",
      "0 Aerosol_Optical_Thickness_550_Land\n",
      "1 Aerosol_Optical_Thickness_550_Land_Best_Estimate\n",
      "2 Aerosol_Optical_Thickness_550_Land_Ocean\n",
      "3 Aerosol_Optical_Thickness_550_Land_Ocean_Best_Estimate\n",
      "4 Aerosol_Optical_Thickness_550_Ocean\n",
      "5 Aerosol_Optical_Thickness_550_Ocean_Best_Estimate\n",
      "6 Aerosol_Optical_Thickness_550_STDV_Land\n",
      "7 Aerosol_Optical_Thickness_550_STDV_Ocean\n",
      "8 Aerosol_Optical_Thickness_QA_Flag_Land\n",
      "9 Aerosol_Optical_Thickness_QA_Flag_Ocean\n",
      "10 Aerosol_Type_Land\n",
      "11 Aerosol_Type_Land_Ocean\n",
      "12 Aerosol_Type_Ocean\n",
      "13 Algorithm_Flag_Land\n",
      "14 Algorithm_Flag_Land_for_test\n",
      "15 Algorithm_Flag_Ocean\n",
      "16 Angstrom_Exponent_Land\n",
      "17 Angstrom_Exponent_Land_Best_Estimate\n",
      "18 Angstrom_Exponent_Land_Ocean\n",
      "19 Angstrom_Exponent_Land_Ocean_Best_Estimate\n",
      "20 Angstrom_Exponent_Ocean\n",
      "21 Angstrom_Exponent_Ocean_Best_Estimate\n",
      "22 Cell_Average_Chl\n",
      "23 Cell_Average_Elevation_Land\n",
      "24 Cell_Average_Elevation_Ocean\n",
      "25 Fine_Mode_Fraction_550_Ocean\n",
      "26 Fine_Mode_Fraction_550_Ocean_Best_Estimate\n",
      "27 Idx_Atrack\n",
      "28 Idx_Xtrack\n",
      "29 Land_Bands\n",
      "30 Latitude\n",
      "31 Longitude\n",
      "32 Number_Of_Pixels_Used_Land\n",
      "33 Number_Of_Pixels_Used_Ocean\n",
      "34 Number_Valid_Pixels\n",
      "35 Ocean_Bands\n",
      "36 Ocean_Sum_Squares\n",
      "37 Precipitable_Water\n",
      "38 Reflectance_Bands\n",
      "39 Relative_Azimuth_Angle\n",
      "40 Scan_Start_Time\n",
      "41 Scattering_Angle\n",
      "42 Solar_Zenith_Angle\n",
      "43 Spectral_Aerosol_Optical_Thickness_Land\n",
      "44 Spectral_Aerosol_Optical_Thickness_Ocean\n",
      "45 Spectral_Single_Scattering_Albedo_Land\n",
      "46 Spectral_Surface_Reflectance\n",
      "47 Spectral_TOA_Reflectance_Land\n",
      "48 Spectral_TOA_Reflectance_Ocean\n",
      "49 TOA_NDVI\n",
      "50 Total_Column_Ozone\n",
      "51 Viewing_Zenith_Angle\n",
      "52 Wind_Direction\n",
      "53 Wind_Speed\n"
     ]
    }
   ],
   "source": [
    "##-- Parameters\n",
    "indir='./data/'\n",
    "#fname=indir+'3B-HHR.MS.MRG.3IMERG.20180218-S000000-E002959.0000.V06A.HDF5'\n",
    "fname=indir+'AERDB_L2_VIIRS_SNPP.A2014067.1936.001.2019056041229.nc'\n",
    "#fname=indir+'AERDB_temp.hdf5'\n",
    "\n",
    "hdf_f = open_hdf5(fname)\n",
    "\n",
    "i=0\n",
    "hdf_f.visit(printname)\n",
    "\n",
    "\n",
    "h5keys=[]\n",
    "hdf_f.visit(h5keys.append)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aerosol_Optical_Thickness_550_Land_Ocean\n",
      "Name: units\n",
      "   Values: b'1'\n",
      "Name: valid_range\n",
      "   Values: [0. 5.]\n",
      "Name: long_name\n",
      "   Values: b'Deep Blue/SOAR aerosol optical thickness at 550 nm over land and ocean'\n",
      "Name: coordinates\n",
      "   Values: b'Longitude Latitude'\n",
      "Name: _FillValue\n",
      "   Values: [-999.]\n",
      "Name: DIMENSION_LIST\n",
      "   Values: [array([<HDF5 object reference>], dtype=object)\n",
      " array([<HDF5 object reference>], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "it=2\n",
    "print(\"\\n{}\".format(h5keys[it]))\n",
    "dset=hdf_f[h5keys[it]]\n",
    "for (name, val) in dset.attrs.items():\n",
    "    print(\"Name: {}\".format(name))\n",
    "    print(\"   Values: {}\".format(val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spectral_Aerosol_Optical_Thickness_Land\n",
      "Name: long_name\n",
      "   Values: b'Deep Blue spectral aerosol optical thickness at 412, 488, and 670 nm over land'\n",
      "Name: units\n",
      "   Values: b'1'\n",
      "Name: coordinates\n",
      "   Values: b'Longitude Latitude'\n",
      "Name: _FillValue\n",
      "   Values: [-999.]\n",
      "Name: valid_range\n",
      "   Values: [0. 5.]\n",
      "Name: DIMENSION_LIST\n",
      "   Values: [array([<HDF5 object reference>], dtype=object)\n",
      " array([<HDF5 object reference>], dtype=object)\n",
      " array([<HDF5 object reference>], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "it=43\n",
    "print(\"\\n{}\".format(h5keys[it]))\n",
    "dset=hdf_f[h5keys[it]]\n",
    "for (name, val) in dset.attrs.items():\n",
    "    print(\"Name: {}\".format(name))\n",
    "    print(\"   Values: {}\".format(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C02c.HDF5_read_write.py3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read HDF5 file and write a few variables to a new hdf5 file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_hdf5(fname):\n",
    "    if not os.path.isfile(fname):\n",
    "        print(\"File does not exist:\"+fname)\n",
    "        sys.exit()\n",
    "\n",
    "    hid=h5py.File(fname,'r')\n",
    "    print(\"Open:\",fname)\n",
    "    return hid\n",
    "\n",
    "\n",
    "def hdf_key_test(f,key1):\n",
    "    if key1 not in list(f.keys()):\n",
    "        print(list(f.keys()))\n",
    "        sys.exit('Key name is not matched: {}'.format(key1))\n",
    "    else:\n",
    "        print('key is available')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##-- Parameters\n",
    "indir='./data/'\n",
    "#fname=indir+'3B-HHR.MS.MRG.3IMERG.20180218-S000000-E002959.0000.V06A.HDF5'\n",
    "fname=indir+'AERDB_L2_VIIRS_SNPP.A2014067.1936.001.2019056041229.nc'\n",
    "\n",
    "h5keys=['Longitude','Latitude','Aerosol_Optical_Thickness_550_Land_Ocean','Spectral_Aerosol_Optical_Thickness_Land']\n",
    "\n",
    "undef = -999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open: ./data/AERDB_L2_VIIRS_SNPP.A2014067.1936.001.2019056041229.nc\n",
      "key is available\n",
      "key is available\n",
      "key is available\n",
      "key is available\n"
     ]
    }
   ],
   "source": [
    "## Open file and test keys\n",
    "hdf_f = open_hdf5(fname)\n",
    "for key in h5keys:\n",
    "    hdf_key_test(hdf_f,key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.dataset.Dataset'> <class 'numpy.ndarray'>\n",
      "(404, 400) (404, 400) (404, 400) (3, 404, 400)\n"
     ]
    }
   ],
   "source": [
    "## Read data\n",
    "lons=hdf_f[h5keys[0]]  ## h5py data array\n",
    "lats=hdf_f[h5keys[1]][:]  ## Now numpy array\n",
    "aot550lo=hdf_f[h5keys[2]][:]\n",
    "saotl=hdf_f[h5keys[3]][:]\n",
    "\n",
    "print(type(lons),type(lats))\n",
    "print(lons.shape,lats.shape,aot550lo.shape,saotl.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rate of Aerosol_Optical_Thickness_550_Land_Ocean = 68.18%\n"
     ]
    }
   ],
   "source": [
    "lons=lons[:]\n",
    "hdf_f.close()\n",
    "\n",
    "udidx= aot550lo==undef\n",
    "print(\"Missing rate of {} = {:.2f}%\".format(h5keys[2],udidx.sum()/aot550lo.reshape(-1).shape[0]*100.))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115376 110172 109938\n",
      "115376 110172 109938\n",
      "115376 110172 109938\n"
     ]
    }
   ],
   "source": [
    "for k in range(saotl.shape[0]):\n",
    "    idx= saotl[k,:,:]==undef\n",
    "\n",
    "    iidx= np.logical_and(idx,udidx)\n",
    "    print(idx.sum(),udidx.sum(),iidx.sum())\n",
    "\n",
    "    saotl[k,~iidx]=undef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Write\n",
    "outdir = indir\n",
    "outfn = outdir+'AERDB_temp.hdf5'\n",
    "with h5py.File(outfn, 'w') as f:\n",
    "    dset1 = f.create_dataset(\"lon\",data=lons)\n",
    "    dset2 = f.create_dataset(\"lat\",data=lats)\n",
    "    dset3 = f.create_dataset(\"Screened_\"+h5keys[3], data=saotl, dtype='f4')\n",
    "\n",
    "    f[\"lon\"].dims[0].label='lon'\n",
    "    f[\"lon\"].dims[1].label='lat'\n",
    "\n",
    "    f[\"lat\"].dims[0].label='lon'\n",
    "    f[\"lat\"].dims[1].label='lat'\n",
    "\n",
    "    f[\"Screened_\"+h5keys[3]].dims[0].label='bands(412, 488, 670)'\n",
    "    f[\"Screened_\"+h5keys[3]].dims[1].label='lon'\n",
    "#    f[\"Screened_\"+h5keys[3]].dims[2].label='lat'\n",
    "    dset3.dims[2].label='lat'\n",
    "    dset3.attrs['_FillValue']=undef\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C03a.NetCDF_file_header_info.py3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print header information of NetCDF file\n",
    "\n",
    "Both NetCDF3 and NetCDF4 formats are supported.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "from subprocess import call\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_netcdf(fname):\n",
    "    if not os.path.isfile(fname):\n",
    "        print(\"File does not exist:\"+fname)\n",
    "        sys.exit()\n",
    "\n",
    "    fid=Dataset(fname,'r')\n",
    "    print(\"Open:\",fname)\n",
    "    return fid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##-- Parameters\n",
    "indir='./data/'\n",
    "#fname=indir+'AERDB_L2_VIIRS_SNPP.A2014067.1936.001.2019056041229.nc'\n",
    "#fname=indir+'AERDB_L2_VIIRS_SNPP.A2014067.1936.001.2019056041229.nc'  #HDF?\n",
    "#File name changed!\n",
    "#fname=indir+'slp_wrfout_d01_2018-02-20_00:00:00.nc'\n",
    "fname=indir+'slp_wrfout_d01_2018-02-20_00-00-00.nc'\n",
    "\n",
    "### Get file name from argument\n",
    "#if len(sys.argv)<2:\n",
    "#    sys.exit(\"Please provide NC file name as an argument!\")\n",
    "#else:\n",
    "#    fname= str(sys.argv[1])   ## [1]: the first argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open: ./data/slp_wrfout_d01_2018-02-20_00-00-00.nc\n",
      "\n",
      "*** NC Format= NETCDF3_CLASSIC\n",
      "\n",
      "*** Global Attributes ***\n",
      "\n",
      "*** Dimensions ***\n",
      "    name = 'Time', size = 1\n",
      "\n",
      "    name = 'south_north', size = 1200\n",
      "\n",
      "    name = 'west_east', size = 1200\n",
      "\n",
      "\n",
      "*** Variables ***\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 SLP(Time, south_north, west_east)\n",
      "    FieldType: 104\n",
      "    MemoryOrder: XYZ\n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT XTIME\n",
      "    units: hPa\n",
      "    description: Sea Level Pressure\n",
      "unlimited dimensions: \n",
      "current shape = (1, 1200, 1200)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 XLAT(Time, south_north, west_east)\n",
      "    coordinates: XLONG XLAT\n",
      "    stagger: \n",
      "    units: degree_north\n",
      "    description: LATITUDE, SOUTH IS NEGATIVE\n",
      "    MemoryOrder: XY \n",
      "    FieldType: 104\n",
      "unlimited dimensions: \n",
      "current shape = (1, 1200, 1200)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 XLONG(Time, south_north, west_east)\n",
      "    coordinates: XLONG XLAT\n",
      "    stagger: \n",
      "    units: degree_east\n",
      "    description: LONGITUDE, WEST IS NEGATIVE\n",
      "    MemoryOrder: XY \n",
      "    FieldType: 104\n",
      "unlimited dimensions: \n",
      "current shape = (1, 1200, 1200)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "nc_f= open_netcdf(fname)\n",
    "print(\"\\n*** NC Format=\",nc_f.data_model)\n",
    "\n",
    "###--- Attributes\n",
    "print(\"\\n*** Global Attributes ***\")\n",
    "nc_attrs= nc_f.ncattrs()\n",
    "for nc_attr in nc_attrs:\n",
    "    print('   {}: {}'.format(nc_attr,nc_f.getncattr(nc_attr)))\n",
    "\n",
    "print(\"\\n*** Dimensions ***\")\n",
    "for nc_dim in nc_f.dimensions:\n",
    "#    print('   Name: {}'.format(nc_dim))\n",
    "    print('   {}'.format(str(nc_f.dimensions[nc_dim]).split(':')[1]))\n",
    "\n",
    "print(\"\\n*** Variables ***\")\n",
    "for var in nc_f.variables:\n",
    "    print(nc_f.variables[var])\n",
    "\n",
    "nc_f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C03b.NetCDF_read_write.py3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "### Read NC files of 4 variables, and write a NC file all together\n",
    "\n",
    "Input files:\n",
    "data/slp_wrfout_d01_2018-02-17_00-00-00.nc\n",
    "data/hgt_1000hPa_wrfout_d01_2018-02-17_00-00-00.nc\n",
    "data/hgt_500hPa_wrfout_d01_2018-02-17_00-00-00.nc\n",
    "data/hgt_200hPa_wrfout_d01_2018-02-17_00-00-00.nc\n",
    "\n",
    "###Every 6 hours for 3 days\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "from subprocess import call\n",
    "from datetime import timedelta, date, datetime\n",
    "from netCDF4 import Dataset, date2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_netcdf(fname):\n",
    "    if not os.path.isfile(fname):\n",
    "        print(\"File does not exist:\"+fname)\n",
    "        sys.exit()\n",
    "\n",
    "    fid=Dataset(fname,'r')\n",
    "    print(\"Open:\",fname)\n",
    "    return fid\n",
    "\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    ### Including end date\n",
    "    for n in range(int((end_date - start_date).days)+1):\n",
    "        yield start_date + timedelta(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###--- Parameters\n",
    "start_date = date(2018,2,17)  ### Start Date\n",
    "end_date = date(2018,2,20)   ### Including this End Date\n",
    "\n",
    "vars = ['slp','hgt_1000hPa','hgt_500hPa','hgt_200hPa']\n",
    "dim_names = ['XLAT','XLONG']\n",
    "indir = './data/'\n",
    "outdir = indir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Time', 'south_north', 'west_east') <class 'numpy.ma.core.MaskedArray'> (1200, 1200)\n",
      "[datetime.datetime(2018, 2, 17, 0, 0), datetime.datetime(2018, 2, 17, 6, 0), datetime.datetime(2018, 2, 17, 12, 0), datetime.datetime(2018, 2, 17, 18, 0)]\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "(4, 4, 1200, 1200)\n",
      "./data/wrfout_d01_2018-02-17.nc is written.\n",
      "('Time', 'south_north', 'west_east') <class 'numpy.ma.core.MaskedArray'> (1200, 1200)\n",
      "[datetime.datetime(2018, 2, 18, 0, 0), datetime.datetime(2018, 2, 18, 6, 0), datetime.datetime(2018, 2, 18, 12, 0), datetime.datetime(2018, 2, 18, 18, 0)]\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "(4, 4, 1200, 1200)\n",
      "./data/wrfout_d01_2018-02-18.nc is written.\n",
      "('Time', 'south_north', 'west_east') <class 'numpy.ma.core.MaskedArray'> (1200, 1200)\n",
      "[datetime.datetime(2018, 2, 19, 0, 0), datetime.datetime(2018, 2, 19, 6, 0), datetime.datetime(2018, 2, 19, 12, 0), datetime.datetime(2018, 2, 19, 18, 0)]\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "hgt_200hPa (4, 1200, 1200)\n",
      "(4, 4, 1200, 1200)\n",
      "./data/wrfout_d01_2018-02-19.nc is written.\n",
      "./data/slp_wrfout_d01_2018-02-20_06-00-00.nc not available\n",
      "./data/slp_wrfout_d01_2018-02-20_12-00-00.nc not available\n",
      "./data/slp_wrfout_d01_2018-02-20_18-00-00.nc not available\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Files are incomplete on 2018-02-20",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Files are incomplete on 2018-02-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "for oneday in daterange(start_date,end_date):\n",
    "    dd=oneday.strftime('%Y-%m-%d')\n",
    "\n",
    "    file_test=False\n",
    "    f_ids=[]\n",
    "    for tt in range(0,24,6):\n",
    "        f_ids.append([])\n",
    "        for vv in vars:\n",
    "            infn=indir+'{}_wrfout_d01_{}_{:02d}-00-00.nc'.format(vv,dd,tt)\n",
    "            #nc_f=open_netcdf(infn)\n",
    "            if not os.path.isfile(infn):\n",
    "                print(infn+\" not available\")\n",
    "                file_test=True\n",
    "                break\n",
    "            else:\n",
    "                fid=Dataset(infn,'r')\n",
    "                f_ids[-1].append(fid)\n",
    "\n",
    "\n",
    "    if file_test:\n",
    "        sys.exit(\"Files are incomplete on {}\".format(dd))\n",
    "    else:\n",
    "        f_id_tmp= f_ids[0][0]\n",
    "        dims = f_id_tmp.variables[vars[0].upper()].dimensions\n",
    "        lats = f_id_tmp.variables['XLAT'][:]\n",
    "        if lats.shape[0]==1:\n",
    "            lats=lats.reshape(lats.shape[1:])\n",
    "        lons = f_id_tmp.variables['XLONG'][:]\n",
    "        if lons.shape[0]==1:\n",
    "            lons=lons.reshape(lons.shape[1:])\n",
    "        print(dims,type(lons),lons.shape)\n",
    "\n",
    "\n",
    "        times = [datetime(oneday.year,oneday.month,oneday.day)+n*timedelta(hours=6) for n in range(len(f_ids))]\n",
    "        print(times)\n",
    "\n",
    "        data=[]\n",
    "        for fids in f_ids:\n",
    "            for i,fid in enumerate(fids):\n",
    "                vname=vars[i].split('_')[0].upper()\n",
    "                if i==0:\n",
    "                    temp=fid.variables[vname][:]\n",
    "                else:\n",
    "                    temp=np.concatenate((temp,fid.variables[vname][:]))\n",
    "\n",
    "            print(vars[i],temp.shape)\n",
    "            data.append(temp)\n",
    "\n",
    "        data=np.asarray(data).astype(np.float32)\n",
    "        print(data.shape)\n",
    "\n",
    "\n",
    "\n",
    "        ### Ready to Create a daily NC file\n",
    "        outfn=outdir+'wrfout_d01_{}.nc'.format(dd)\n",
    "        ncfw= Dataset(outfn, \"w\", format=\"NETCDF4\")\n",
    "\n",
    "        ## Dimensions\n",
    "        ln=ncfw.createDimension('lon',lons.shape[0])\n",
    "        lt=ncfw.createDimension('lat',lats.shape[1])\n",
    "        lv=ncfw.createDimension('lev',3)\n",
    "        tm=ncfw.createDimension('time',len(times))\n",
    "\n",
    "        lonsnc = ncfw.createVariable('lon','f4',('lon','lat',))\n",
    "        latsnc = ncfw.createVariable('lat','f4',('lat','lat',))\n",
    "        levsnc = ncfw.createVariable('lev','f4',('lev',))\n",
    "        timenc = ncfw.createVariable('time','f8',('time',))\n",
    "\n",
    "        lonsnc[:]=lons; latsnc[:]=lats\n",
    "        lonsnc.units = 'degrees_east'; latsnc.units = 'degrees_north'\n",
    "        levsnc[:]=[1000,500,200]\n",
    "        levsnc.units = 'hPa'\n",
    "\n",
    "        timenc.units = 'hours since 0001-01-01 00:00:00.0'\n",
    "        timenc.calendar = 'gregorian'\n",
    "        timenc[:] = date2num(times, timenc.units, calendar=timenc.calendar)\n",
    "\n",
    "        ## Data variables\n",
    "        slpnc = ncfw.createVariable('SLP','f4',('time','lat','lon'))\n",
    "        slpnc[:] = data[:,0,:,:]\n",
    "        hgtnc = ncfw.createVariable('HGT','f4',('time','lev','lat','lon'))\n",
    "        hgtnc[:] = data[:,1:,:,:]\n",
    "\n",
    "        ## Attributions\n",
    "        ncfw.description = 'Model output on {}'.format(dd)\n",
    "\n",
    "        ## Close file\n",
    "        print(\"{} is written.\".format(outfn))\n",
    "        ncfw.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sst_map+masked_array.py3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "from subprocess import call\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_file_read2mtx(fname,dtype=np.float32):\n",
    "    \"\"\" Open a binary file, and read data \n",
    "        fname : file name\n",
    "        dtype   : data type; np.float32 or np.float64, etc. \"\"\"\n",
    "\n",
    "    if not os.path.isfile(fname):\n",
    "        #print( \"File does not exist:\"+fname); sys.exit()\n",
    "        sys.exit(\"File does not exist:\"+fname)\n",
    "\n",
    "    #fd=open(fname,'rb')\n",
    "    with open(fname,'rb') as f:\n",
    "        bin_mat = np.fromfile(file=f,dtype=dtype)\n",
    "    #fd.close() ### Not needed with \"with\"\n",
    "\n",
    "    return bin_mat\n",
    "\n",
    "from math import ceil\n",
    "def lon_deg2x(lon,lon0,dlon):\n",
    "    x=ceil((lon-lon0)/dlon)\n",
    "    if lon0<0 and lon>180:\n",
    "        x-= int(360/dlon)\n",
    "    if lon0>0 and lon<0:\n",
    "        x+= int(360/dlon)\n",
    "\n",
    "    return x\n",
    "lat_deg2y = lambda lat,lat0,dlat: ceil((lat-lat0)/dlat)\n",
    "\n",
    "def map_common(ax1,gl_loc=[True,True,False,True],gl_dlon=60,gl_dlat=30):\n",
    "    ax1.set_title(subtit,x=0.,ha='left',fontsize=13,stretch='semi-condensed')\n",
    "    ax1.coastlines(color='silver',linewidth=1.)\n",
    "\n",
    "    gl = ax1.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                       linewidth=0.6, color='gray', alpha=0.5, linestyle='--')\n",
    "\n",
    "    gl.ylabels_left = gl_loc[0]\n",
    "    gl.ylabels_right = gl_loc[1]\n",
    "    gl.xlabels_top = gl_loc[2]\n",
    "    gl.xlabels_bottom = gl_loc[3]\n",
    "\n",
    "    gl.xlocator = FixedLocator(range(-180+gl_dlon,361,gl_dlon)) #[0,60,180,240,360]) #np.arange(-180,181,60))\n",
    "    gl.ylocator = MultipleLocator(gl_dlat)\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 11, 'color': 'k'}\n",
    "    gl.ylabel_style = {'size': 11, 'color': 'k'}\n",
    "\n",
    "def add_colorbar(cb_ax,cblab,horizontal=True):\n",
    "\n",
    "    global clmin, clmax\n",
    "    tt=np.arange(clmin,clmax+1,4)\n",
    "    #tt2=[str(x)+'%' for x in tt]\n",
    "    if horizontal:\n",
    "        cb = fig.colorbar(cs,cax=cb_ax,orientation='horizontal',ticks=tt,extend='both')\n",
    "        cb.ax.set_xticklabels(tt,size=11)\n",
    "        cb.ax.set_xlabel(cblab)\n",
    "    else:\n",
    "        cb = fig.colorbar(cs,cax=cb_ax,orientation='vertical',ticks=tt,extend='both')\n",
    "        cb.ax.set_yticklabels(tt,size=11)\n",
    "        cb.ax.set_ylabel(cblab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348, 180, 360)\n"
     ]
    }
   ],
   "source": [
    "###---- Main\n",
    "\n",
    "##-- Parameters\n",
    "indir='./data/'\n",
    "fname=indir+'HadISST1.sample.348x180x360.f32dat'\n",
    "\n",
    "nt=348 ### Monthly for 29 years\n",
    "nlon=360; lon0=0.5; dlon=1.\n",
    "nlat=180; lat0=-89.5; dlat=1.\n",
    "\n",
    "undef= -9999.\n",
    "\n",
    "##-- Read binary file\n",
    "sst=bin_file_read2mtx(fname)  ### \"dtype=np.float32\" is omitted. \n",
    "sst=sst.reshape([nt,nlat,nlon])\n",
    "print(sst.shape)\n",
    "\n",
    "###--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 360) 33219\n",
      "Min and Max of Mean SST= 1.4067242 29.744629\n"
     ]
    }
   ],
   "source": [
    "##-- Identify missings\n",
    "msidx= sst<-100\n",
    "msidx=msidx.sum(axis=0).astype(bool) ### For identify gridcells having any missings for all time\n",
    "print(msidx.shape,msidx.sum())\n",
    "\n",
    "sstmean= sst.mean(axis=0)\n",
    "sstmean[msidx]=undef\n",
    "sm_max,sm_min=sstmean[~msidx].max(), sstmean[~msidx].min()\n",
    "print(\"Min and Max of Mean SST=\",sm_min, sm_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 30] [130, 165]\n",
      "(35, 90)\n"
     ]
    }
   ],
   "source": [
    "##-- Sampling for limited regiosn \n",
    "lon_deg_range=[-60,30]\n",
    "lat_deg_range=[40,75]\n",
    "\n",
    "lon_idx=[lon_deg2x(x,lon0,dlon) for x in lon_deg_range]; nlon2=lon_idx[1]-lon_idx[0]\n",
    "lat_idx=[lat_deg2y(y,lat0,dlat) for y in lat_deg_range]; nlat2=lat_idx[1]-lat_idx[0]\n",
    "print(lon_idx, lat_idx)\n",
    "### In the case of trouble of lon_idx\n",
    "### lon_idx[1] < lon_idx[0]\n",
    "### Now need to make lon-list\n",
    "\n",
    "lon_list=list(range(lon_idx[0],nlon,1))+list(range(lon_idx[1]))\n",
    "sstmean2=sstmean[lat_idx[0]:lat_idx[1],lon_list]\n",
    "print(sstmean2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ma.core.MaskedArray'>\n"
     ]
    }
   ],
   "source": [
    "### The other maskig method\n",
    "sst_rg=sst[:,lat_idx[0]:lat_idx[1],lon_list]\n",
    "sst_rg=np.ma.masked_less(sst_rg,-100)\n",
    "print(type(sst_rg))\n",
    "sstmean_ma=sst_rg.mean(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:3: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n",
      "    handle._run()\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2666, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/discover/nobackup/jyoo8/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cartopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-afb62ec01c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoMinorLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFixedLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultipleLocator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mccrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridliner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLONGITUDE_FORMATTER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLATITUDE_FORMATTER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cartopy'"
     ]
    }
   ],
   "source": [
    "###--- Map Plot\n",
    "import matplotlib            ### Discover only\n",
    "matplotlib.use('TkAgg')      ### Discover only\n",
    "import matplotlib.colors as cls\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator, FixedLocator, MultipleLocator\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ccrs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-10a77cca8cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m##-- Top Panel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mly\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mccrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlateCarree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentral_longitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m### Now it's GeoAxes, not just Axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0msubtit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'(a) Global Mean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ccrs' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 612x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "fig.set_size_inches(8.5,8)  ## (xsize,ysize)\n",
    "suptit=\"SST Map\"\n",
    "fig.suptitle(suptit,fontsize=17,y=0.98,stretch='semi-condensed') ## x=0., ha='left'\n",
    "\n",
    "left,right,top,bottom=0.05,0.95,0.925,0.05\n",
    "iix=left; gapx=0.02; npnx=2\n",
    "lx=(right-iix-gapx*(npnx-1))/float(npnx)\n",
    "iiy=top; gapy=0.12; npny=2\n",
    "ly=(iiy-bottom-gapy*(npny-1))/float(npny)\n",
    "\n",
    "lx0=lx*npnx+gapx*(npnx-1)\n",
    "ix=iix; iy=iiy-ly\n",
    "\n",
    "cm = plt.cm.get_cmap('nipy_spectral')\n",
    "cm.set_bad('0.4')\n",
    "cm.set_under('0.8')\n",
    "\n",
    "lons_data=np.arange(lon0,360.1,dlon)\n",
    "lats_data=np.arange(lat0,90.1,dlat)\n",
    "\n",
    "clmin,clmax= int(sm_min)+1,int(sm_max)+1\n",
    "clevels= np.linspace(clmin,clmax,51)\n",
    "\n",
    "##-- Top Panel\n",
    "ax1=fig.add_axes([ix,iy,lx0,ly],projection=ccrs.PlateCarree(central_longitude=180))  ### Now it's GeoAxes, not just Axes\n",
    "\n",
    "subtit='(a) Global Mean'\n",
    "\n",
    "props = dict(vmin=clmin,vmax=clmax,cmap=cm,alpha=0.9,transform=ccrs.PlateCarree())\n",
    "cs=ax1.contourf(lons_data,lats_data,sstmean, clevels,**props)\n",
    "#cs=ax1.pcolormesh(lons_data,lats_data,sstmean, **props)\n",
    "\n",
    "map_common(ax1)\n",
    "\n",
    "ax1.set_aspect('auto')\n",
    "\n",
    "### Add colorbar\n",
    "#- Get position from previous subplot\n",
    "pos1 = ax1.get_position().bounds  ##<= (left,bottom,width,height)\n",
    "cb_ax = fig.add_axes([pos1[0],pos1[1]-pos1[3]/6.,pos1[2],pos1[3]/15.])  ##<= (left,bottom,width,height)\n",
    "cblab = \"Temperature (\\u00B0C)\"\n",
    "add_colorbar(cb_ax,cblab,horizontal=True)\n",
    "\n",
    "\n",
    "\n",
    "##-- Bottom Panels\n",
    "\n",
    "lons_data2=np.arange(lon_deg_range[0]+0.5,lon_deg_range[1],dlon)\n",
    "lats_data2=np.arange(lat_deg_range[0]+0.5,lat_deg_range[1],dlat)\n",
    "\n",
    "iy=iy-gapy-ly\n",
    "ax2=fig.add_axes([ix,iy,lx,ly],\n",
    "                 projection=ccrs.PlateCarree(central_longitude=-15))  ### Now it's GeoAxes, not just Axes \n",
    "ax2.set_extent([lon_deg_range[0]-10,lon_deg_range[1]+10,lat_deg_range[0]-5,lat_deg_range[1]+5],ccrs.PlateCarree())\n",
    "\n",
    "subtit='(b) Masking All missings'\n",
    "\n",
    "props = dict(vmin=clmin,vmax=clmax,cmap=cm,alpha=0.9,transform=ccrs.PlateCarree())\n",
    "cs=ax2.pcolormesh(lons_data2,lats_data2,sstmean2, **props)\n",
    "\n",
    "map_common(ax2,gl_loc=[True,False,False,True],gl_dlon=15,gl_dlat=10)\n",
    "\n",
    "ax2.set_aspect('auto')\n",
    "\n",
    "##-- Bottom Right\n",
    "ix=ix+lx+gapx\n",
    "ax3=fig.add_axes([ix,iy,lx,ly],\n",
    "                 projection=ccrs.PlateCarree(central_longitude=-15))  ### Now it's GeoAxes, not just Axes \n",
    "ax3.set_extent([lon_deg_range[0]-10,lon_deg_range[1]+10,lat_deg_range[0]-5,lat_deg_range[1]+5],ccrs.PlateCarree())\n",
    "\n",
    "subtit='(c) Using masked array'\n",
    "\n",
    "props = dict(vmin=clmin,vmax=clmax,cmap=cm,alpha=0.9,transform=ccrs.PlateCarree())\n",
    "cs=ax3.pcolormesh(lons_data2,lats_data2,sstmean_ma, **props)\n",
    "\n",
    "map_common(ax3,gl_loc=[False,True,False,True],gl_dlon=15,gl_dlat=10)\n",
    "\n",
    "#ax3.set_aspect('auto')\n",
    "\n",
    "###--- Save Fig\n",
    "#Change output directory and file name as wanted\n",
    "outdir = \"/discover/nobackup/jyoo8/py3_lecture_2019/Pics/\"\n",
    "fnout = \"sst_map_myex1.png\"\n",
    "\n",
    "### Show or Save\n",
    "plt.show()\n",
    "#plt.savefig(outdir+fnout,bbox_inches='tight',dpi=175)\n",
    "#plt.savefig(outdir+fnout,dpi=160)\n",
    "\n",
    "if os.path.isfile(outdir+fnout) and not os.path.isfile('./Pics/'+fnout):\n",
    "    call([\"ln\",\"-s\",outdir+fnout,\"./Pics/\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
